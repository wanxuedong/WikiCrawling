脚本简介：
本脚本用于实现对维基百科和百度百科的数据抓取
现仅实现维基百科的部分数据抓取
预计上手时长：学习python：2天；学习BeautifulSoup：2天；完成维基百科简单数据抓取：1+天

爬取简要流程：
1.从excel包下的countrys.xls中读取需要抓取的国家/省份
2.根据维基百科和国家/省份的链接拼接进行网页数据的抓取
3.将抓取的存储到excel包下的result.xls文件中

包介绍：
一：excel（原始excel和获取结果的存储文件）
countrys.xls：数据抓取的国家/省份原始数据，仅用来读取
result.xls：抓取到的采样数据存储在该文件中，每次抓取，数据会不断追加

二：platforms（各平台抓取实现脚本）
Wiki.py:用于抓取维基百科平台脚本实现

三：record（抓取过程中临时存储的数据和日志）
wiki.txt:本次抓取的全部维基百科的数据，每次重新开始抓取，之前的内容会清空
baidu.txt:本次抓取的全部百度百科的数据，每次重新开始抓取，之前的内容会清空
log.txt：抓取的全流程和相关错误提示，每次重新开始抓取，之前的内容会清空
error.txt：抓取的仅相关错误提示，每次重新开始抓取，之前的内容会清空

四：upload（网络请求）
NetControl.py:网络请求实现

五：utils（工具包）
ExcelParser.py:Excel读取和写入工具
langconv.py,zh_wiki.py:用于实现繁体字转简体字或简体字转繁体字

技术点：
1.python脚本实现，参考文档：https://www.runoob.com/python3/python3-set.html
2.网络内容解析通过BeautifulSoup实现，参考文档：https://beautifulsoup.readthedocs.io/zh_CN/v4.4.0/
3.Excel的读取写入使用通过：xlrd，xlwt，xlutils，注意：在读取和写入指定excel的过程中，Excel不可以处于打开状态，否则会出现权限冲突，且只能操作.xls，不能操作.xlsx
4.繁体字转简体字，langconv.py和zh_wiki.py

快速上手：
从Application.py开始，通过调用Wiki.run(1,-1)，进行抓取维基百科的数据，根据excel包下countrys.xls提供的行政区划进行挨行数据抓取，
本地抓取的过程日志记录和获取的数据存储在record包下，并将抓取的数据存储在excel包下result.xls中，当本地抓取因异常终止时，可以更改
调用Wiki.run(1,-1)的run方法第一个参数传入的数字，跳过已经抓取到的数据，抓取到数据也会自动追加在excel包下result.xls文件中，如果觉得数据有错误，
可以将内容全部删除，再重新爬取

注意：一直提示"网络请求异常"时，请检查网络